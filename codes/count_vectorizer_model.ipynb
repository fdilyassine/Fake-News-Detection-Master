{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import os\n",
    "import pickle\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (accuracy_score, f1_score, precision_score,\n",
    "                             recall_score)\n",
    "from sklearn.model_selection import (GridSearchCV, KFold, RandomizedSearchCV,\n",
    "                                     learning_curve)\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\yassi.DESKTOP-5N\n",
      "[nltk_data]     OV12J\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Creating a list of stopwords\n",
    "nltk.download('stopwords')\n",
    "stopwords_list = list(stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to display the evaluation metrics of the different models\n",
    "def show_eval_scores(model, test_set, model_name):\n",
    "\n",
    "    y_pred = model.predict(test_set['news'])\n",
    "    y_true = test_set['label']\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    print('Report for ---> {}'.format(model_name))\n",
    "    print('Accuracy is: {}'.format(accuracy))\n",
    "    print('F1 score is: {}'.format(f1))\n",
    "    print('Precision score is: {}'.format(precision))\n",
    "    print('Recall score is: {}'.format(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the datasets\n",
    "train_data = pd.read_csv('../datasets/train.csv')\n",
    "valid_data = pd.read_csv('../datasets/valid.csv')\n",
    "test_data = pd.read_csv('../datasets/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viewing random rows of all the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>news</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3842</th>\n",
       "      <td>True</td>\n",
       "      <td>Polling shows that nearly 74 percent of Nation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6480</th>\n",
       "      <td>False</td>\n",
       "      <td>I left the city with $43 million in the bank.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4521</th>\n",
       "      <td>False</td>\n",
       "      <td>Says she couldn't take stimulus money because ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4026</th>\n",
       "      <td>True</td>\n",
       "      <td>The United States is the only industrialized c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10111</th>\n",
       "      <td>False</td>\n",
       "      <td>The Health Care and Education Reconciliation A...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                               news\n",
       "3842    True  Polling shows that nearly 74 percent of Nation...\n",
       "6480   False      I left the city with $43 million in the bank.\n",
       "4521   False  Says she couldn't take stimulus money because ...\n",
       "4026    True  The United States is the only industrialized c...\n",
       "10111  False  The Health Care and Education Reconciliation A..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>news</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>True</td>\n",
       "      <td>Al-Qaida has grown fourfold in five years.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>True</td>\n",
       "      <td>Under the clear letter of the law, (Justice Cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>True</td>\n",
       "      <td>For immigrants with visa overstays, we make no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1047</th>\n",
       "      <td>True</td>\n",
       "      <td>The governors budget proposal reduces the stat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1155</th>\n",
       "      <td>True</td>\n",
       "      <td>Says the director of NASA says its main missio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               news\n",
       "824    True         Al-Qaida has grown fourfold in five years.\n",
       "548    True  Under the clear letter of the law, (Justice Cl...\n",
       "870    True  For immigrants with visa overstays, we make no...\n",
       "1047   True  The governors budget proposal reduces the stat...\n",
       "1155   True  Says the director of NASA says its main missio..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>news</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>True</td>\n",
       "      <td>The Fed created $1.2 trillion out of nothing, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>True</td>\n",
       "      <td>Says Rick Scott stripped women of access to pu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>True</td>\n",
       "      <td>Says NFL Commissioner Roger Goodell interviewe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>True</td>\n",
       "      <td>The federal government reviewed and verified h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>True</td>\n",
       "      <td>In 1981, Matagorda, Brazoria, and Galveston Co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               news\n",
       "38    True  The Fed created $1.2 trillion out of nothing, ...\n",
       "734   True  Says Rick Scott stripped women of access to pu...\n",
       "138   True  Says NFL Commissioner Roger Goodell interviewe...\n",
       "128   True  The federal government reviewed and verified h...\n",
       "700   True  In 1981, Matagorda, Brazoria, and Galveston Co..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: (10240, 2)\n",
      "Valid dataset size: (1284, 2)\n",
      "Test dataset size: (1267, 2)\n"
     ]
    }
   ],
   "source": [
    "print('Train dataset size: {}'.format(train_data.shape))\n",
    "print('Valid dataset size: {}'.format(valid_data.shape))\n",
    "print('Test dataset size: {}'.format(test_data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining train_data and valid_data into a single training set as GridSearchCV with 5 fold cross validation will be used for hyperparameter tuning the different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (11524, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>news</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8138</th>\n",
       "      <td>True</td>\n",
       "      <td>Were the only advanced democracy in the world ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2271</th>\n",
       "      <td>True</td>\n",
       "      <td>Says under Mayor Cory Booker, Newark has seen ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9234</th>\n",
       "      <td>True</td>\n",
       "      <td>Dan Webster would force victims of rape and in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7441</th>\n",
       "      <td>True</td>\n",
       "      <td>Rep. Paul Ryans budget proposal cuts nothing f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3465</th>\n",
       "      <td>False</td>\n",
       "      <td>(Big banks) have invested over $300,000 in (Jo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               news\n",
       "8138   True  Were the only advanced democracy in the world ...\n",
       "2271   True  Says under Mayor Cory Booker, Newark has seen ...\n",
       "9234   True  Dan Webster would force victims of rape and in...\n",
       "7441   True  Rep. Paul Ryans budget proposal cuts nothing f...\n",
       "3465  False  (Big banks) have invested over $300,000 in (Jo..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set = pd.concat([train_data, valid_data], ignore_index=True)\n",
    "print('Training set size: {}'.format(training_set.shape))\n",
    "training_set.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a CountVectorizer object and analyzing the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "countV = CountVectorizer()\n",
    "train_count = countV.fit_transform(training_set['news'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building and tuning Logistic Regression pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_pipeline = Pipeline([\n",
    "#     ('lrCV', CountVectorizer(stop_words=stopwords_list)),\n",
    "#     ('lr_clf', LogisticRegression(random_state=42, n_jobs=-1))\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid = [\n",
    "#     {\n",
    "#         'lrCV__lowercase': [True, False],\n",
    "#         'lrCV__ngram_range': [(1, 1), (1, 2), (1, 3), (1, 4)],\n",
    "#         'lr_clf__C': [0.0001, 0.00005, 0.00001]\n",
    "#     }\n",
    "# ]\n",
    "\n",
    "# lr_gs = GridSearchCV(lr_pipeline, param_grid, scoring='f1', n_jobs=-1, cv=5, verbose=1)\n",
    "# lr_gs.fit(training_set['news'], training_set['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pipeline = Pipeline([\n",
    "    ('lrCV', CountVectorizer(stop_words=stopwords_list, lowercase=True, ngram_range=(1, 1))),\n",
    "    ('lr_clf', LogisticRegression(C=0.0001,random_state=42, n_jobs=-1))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('lrCV',\n",
       "                 CountVectorizer(stop_words=['i', 'me', 'my', 'myself', 'we',\n",
       "                                             'our', 'ours', 'ourselves', 'you',\n",
       "                                             \"you're\", \"you've\", \"you'll\",\n",
       "                                             \"you'd\", 'your', 'yours',\n",
       "                                             'yourself', 'yourselves', 'he',\n",
       "                                             'him', 'his', 'himself', 'she',\n",
       "                                             \"she's\", 'her', 'hers', 'herself',\n",
       "                                             'it', \"it's\", 'its', 'itself', ...])),\n",
       "                ('lr_clf',\n",
       "                 LogisticRegression(C=0.0001, n_jobs=-1, random_state=42))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_pipeline.fit(training_set['news'], training_set['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report for ---> Logistic Regression Count Vectorizer\n",
      "Accuracy is: 0.56353591160221\n",
      "F1 score is: 0.7208480565371024\n",
      "Precision score is: 0.56353591160221\n",
      "Recall score is: 1.0\n"
     ]
    }
   ],
   "source": [
    "show_eval_scores(lr_pipeline, test_data, 'Logistic Regression Count Vectorizer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building and tuning Naive Bayes pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nb_pipeline = Pipeline([\n",
    "#     ('nb_CV', CountVectorizer(stop_words=stopwords_list)),\n",
    "#     ('nb_clf', MultinomialNB())\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid = {\n",
    "#     'nb_clf__alpha': [i/10.0 for i in range(60, 71)],\n",
    "#     'nb_CV__lowercase': [True, False],\n",
    "#     'nb_CV__ngram_range': [(1, 1), (1, 2), (1, 3), (1, 4)]\n",
    "# }\n",
    "\n",
    "# nb_gs = GridSearchCV(nb_pipeline, param_grid, scoring = 'f1', cv=5, n_jobs=-1, verbose=1)\n",
    "# nb_gs.fit(training_set['news'], training_set['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nb_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nb_gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_pipeline = Pipeline([\n",
    "    ('nb_CV', CountVectorizer(stop_words=stopwords_list, lowercase=True, ngram_range=(1, 4))),\n",
    "    ('nb_clf', MultinomialNB(alpha=6.8))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('nb_CV',\n",
       "                 CountVectorizer(ngram_range=(1, 4),\n",
       "                                 stop_words=['i', 'me', 'my', 'myself', 'we',\n",
       "                                             'our', 'ours', 'ourselves', 'you',\n",
       "                                             \"you're\", \"you've\", \"you'll\",\n",
       "                                             \"you'd\", 'your', 'yours',\n",
       "                                             'yourself', 'yourselves', 'he',\n",
       "                                             'him', 'his', 'himself', 'she',\n",
       "                                             \"she's\", 'her', 'hers', 'herself',\n",
       "                                             'it', \"it's\", 'its', 'itself', ...])),\n",
       "                ('nb_clf', MultinomialNB(alpha=6.8))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_pipeline.fit(training_set['news'], training_set['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report for ---> Naive Bayes Count Vectorizer\n",
      "Accuracy is: 0.6203630623520127\n",
      "F1 score is: 0.7326292384658143\n",
      "Precision score is: 0.6073732718894009\n",
      "Recall score is: 0.9229691876750701\n"
     ]
    }
   ],
   "source": [
    "show_eval_scores(nb_pipeline, test_data, 'Naive Bayes Count Vectorizer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building and tuning SVM classifier pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm_pipeline = Pipeline([\n",
    "#     ('svm_CV', CountVectorizer(stop_words=stopwords_list)),\n",
    "#     ('svm_clf', SVC(random_state=42))\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid = [\n",
    "#     {\n",
    "#         'svm_CV__lowercase': [True, False],\n",
    "#         'svm_CV__ngram_range': [(1, 1), (1, 2), (1, 3), (1, 4)],\n",
    "#         'svm_clf__kernel': ['poly'],\n",
    "#         'svm_clf__degree': [1, 2, 3]\n",
    "#     },\n",
    "#     {\n",
    "#         'svm_CV__lowercase': [True, False],\n",
    "#         'svm_CV__ngram_range': [(1, 1), (1, 2), (1, 3), (1, 4)],\n",
    "#         'svm_clf__kernel': ['rbf'],\n",
    "#         'svm_clf__gamma': [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "#     }\n",
    "# ]\n",
    "\n",
    "# svm_gs = GridSearchCV(svm_pipeline, param_grid, scoring='f1', n_jobs=-1, cv=5, verbose=1)\n",
    "# svm_gs.fit(training_set['news'], training_set['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm_gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_pipeline = Pipeline([\n",
    "    ('svm_CV', CountVectorizer(stop_words=stopwords_list, lowercase=False, ngram_range=(1, 1))),\n",
    "    ('svm_clf', SVC(random_state=42, gamma=1.0, kernel='rbf'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('svm_CV',\n",
       "                 CountVectorizer(lowercase=False,\n",
       "                                 stop_words=['i', 'me', 'my', 'myself', 'we',\n",
       "                                             'our', 'ours', 'ourselves', 'you',\n",
       "                                             \"you're\", \"you've\", \"you'll\",\n",
       "                                             \"you'd\", 'your', 'yours',\n",
       "                                             'yourself', 'yourselves', 'he',\n",
       "                                             'him', 'his', 'himself', 'she',\n",
       "                                             \"she's\", 'her', 'hers', 'herself',\n",
       "                                             'it', \"it's\", 'its', 'itself', ...])),\n",
       "                ('svm_clf', SVC(gamma=1.0, random_state=42))])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_pipeline.fit(training_set['news'], training_set['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report for ---> SVM Classifier Count Vectorizer\n",
      "Accuracy is: 0.5666929755327546\n",
      "F1 score is: 0.7211782630777045\n",
      "Precision score is: 0.5657370517928287\n",
      "Recall score is: 0.9943977591036415\n"
     ]
    }
   ],
   "source": [
    "show_eval_scores(svm_pipeline, test_data, 'SVM Classifier Count Vectorizer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building and Tuning Random Forest Classifier pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_pipeline = Pipeline([\n",
    "#     ('rf_CV', CountVectorizer(stop_words=stopwords_list)),\n",
    "#     ('rf_clf', RandomForestClassifier(n_jobs=-1, random_state=42))\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid = {\n",
    "#     'rf_CV__lowercase': [True, False],\n",
    "#     'rf_CV__ngram_range': [(1, 1), (1, 2), (1, 3), (1, 4), (1, 5)],\n",
    "#     'rf_clf__n_estimators': [200, 300, 400, 500],\n",
    "#     'rf_clf__max_depth': [i for i in range(8, 13)],\n",
    "#     'rf_clf__max_features': ['auto', 'sqrt', 'log2']\n",
    "# }\n",
    "# rf_gs = GridSearchCV(rf_pipeline, param_grid, scoring='f1', cv=5, verbose=1, n_jobs=-1)\n",
    "# rf_gs.fit(training_set['news'], training_set['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pipeline = Pipeline([\n",
    "    ('rf_CV', CountVectorizer(stop_words=stopwords_list, lowercase=False, ngram_range=(1, 1))),\n",
    "    ('rf_clf', RandomForestClassifier(max_depth=12, n_estimators=300, n_jobs=-1, random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('rf_CV',\n",
       "                 CountVectorizer(lowercase=False,\n",
       "                                 stop_words=['i', 'me', 'my', 'myself', 'we',\n",
       "                                             'our', 'ours', 'ourselves', 'you',\n",
       "                                             \"you're\", \"you've\", \"you'll\",\n",
       "                                             \"you'd\", 'your', 'yours',\n",
       "                                             'yourself', 'yourselves', 'he',\n",
       "                                             'him', 'his', 'himself', 'she',\n",
       "                                             \"she's\", 'her', 'hers', 'herself',\n",
       "                                             'it', \"it's\", 'its', 'itself', ...])),\n",
       "                ('rf_clf',\n",
       "                 RandomForestClassifier(max_depth=12, n_estimators=300,\n",
       "                                        n_jobs=-1, random_state=42))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_pipeline.fit(training_set['news'], training_set['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report for ---> Random Forest Classifier Count Vectorizer\n",
      "Accuracy is: 0.5651144435674822\n",
      "F1 score is: 0.7215765538150581\n",
      "Precision score is: 0.5644268774703557\n",
      "Recall score is: 1.0\n"
     ]
    }
   ],
   "source": [
    "show_eval_scores(rf_pipeline, test_data, 'Random Forest Classifier Count Vectorizer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building a Voting Classifier using the above created models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_voting_pipeline = Pipeline([\n",
    "    ('rf_CV', CountVectorizer(stop_words=stopwords_list, lowercase=False, ngram_range=(1, 1))),\n",
    "    ('rf_clf', RandomForestClassifier(max_depth=12, n_estimators=300, n_jobs=-1, random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_voting_pipeline = Pipeline([\n",
    "    ('svm_CV', CountVectorizer(stop_words=stopwords_list, lowercase=False, ngram_range=(1, 1))),\n",
    "    ('svm_clf', SVC(random_state=42, gamma=1.0, kernel='rbf', probability=True))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_voting_pipeline = Pipeline([\n",
    "    ('nb_CV', CountVectorizer(stop_words=stopwords_list, lowercase=True, ngram_range=(1, 4))),\n",
    "    ('nb_clf', MultinomialNB(alpha=6.8))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_voting_pipeline = Pipeline([\n",
    "    ('lrCV', CountVectorizer(stop_words=stopwords_list, lowercase=True, ngram_range=(1, 1))),\n",
    "    ('lr_clf', LogisticRegression(C=0.0001,random_state=42, n_jobs=-1))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_classifier = VotingClassifier(estimators=[\n",
    "    ('lr', lr_voting_pipeline), ('nb', nb_voting_pipeline),\n",
    "    ('svm', svm_voting_pipeline), ('rf', rf_voting_pipeline)], voting='soft', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette Ã©tape prends du temps (10 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr',\n",
       "                              Pipeline(steps=[('lrCV',\n",
       "                                               CountVectorizer(stop_words=['i',\n",
       "                                                                           'me',\n",
       "                                                                           'my',\n",
       "                                                                           'myself',\n",
       "                                                                           'we',\n",
       "                                                                           'our',\n",
       "                                                                           'ours',\n",
       "                                                                           'ourselves',\n",
       "                                                                           'you',\n",
       "                                                                           \"you're\",\n",
       "                                                                           \"you've\",\n",
       "                                                                           \"you'll\",\n",
       "                                                                           \"you'd\",\n",
       "                                                                           'your',\n",
       "                                                                           'yours',\n",
       "                                                                           'yourself',\n",
       "                                                                           'yourselves',\n",
       "                                                                           'he',\n",
       "                                                                           'him',\n",
       "                                                                           'his',\n",
       "                                                                           'himself',\n",
       "                                                                           'she',\n",
       "                                                                           \"she's\",\n",
       "                                                                           'her',\n",
       "                                                                           'hers',\n",
       "                                                                           'herself',\n",
       "                                                                           'it',\n",
       "                                                                           \"it's\",\n",
       "                                                                           'its',\n",
       "                                                                           'itself', ...])),\n",
       "                                              ('lr_clf',\n",
       "                                               LogisticRegression(C=0...\n",
       "                                                               stop_words=['i',\n",
       "                                                                           'me',\n",
       "                                                                           'my',\n",
       "                                                                           'myself',\n",
       "                                                                           'we',\n",
       "                                                                           'our',\n",
       "                                                                           'ours',\n",
       "                                                                           'ourselves',\n",
       "                                                                           'you',\n",
       "                                                                           \"you're\",\n",
       "                                                                           \"you've\",\n",
       "                                                                           \"you'll\",\n",
       "                                                                           \"you'd\",\n",
       "                                                                           'your',\n",
       "                                                                           'yours',\n",
       "                                                                           'yourself',\n",
       "                                                                           'yourselves',\n",
       "                                                                           'he',\n",
       "                                                                           'him',\n",
       "                                                                           'his',\n",
       "                                                                           'himself',\n",
       "                                                                           'she',\n",
       "                                                                           \"she's\",\n",
       "                                                                           'her',\n",
       "                                                                           'hers',\n",
       "                                                                           'herself',\n",
       "                                                                           'it',\n",
       "                                                                           \"it's\",\n",
       "                                                                           'its',\n",
       "                                                                           'itself', ...])),\n",
       "                                              ('rf_clf',\n",
       "                                               RandomForestClassifier(max_depth=12,\n",
       "                                                                      n_estimators=300,\n",
       "                                                                      n_jobs=-1,\n",
       "                                                                      random_state=42))]))],\n",
       "                 n_jobs=-1, voting='soft')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_classifier.fit(training_set['news'], training_set['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report for ---> Voting Classifier(soft) Count Vectorizer\n",
      "Accuracy is: 0.6045777426992897\n",
      "F1 score is: 0.7319422150882826\n",
      "Precision score is: 0.5922077922077922\n",
      "Recall score is: 0.957983193277311\n"
     ]
    }
   ],
   "source": [
    "show_eval_scores(voting_classifier, test_data, 'Voting Classifier(soft) Count Vectorizer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the voting classifier model for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(voting_classifier, open(os.path.join('../models', 'voting_classifier_count_vectorizer.pkl'), 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "cf2fc48634cd6cd67b00e85e4819c226a6a3a164ad0f8f75761705102dfa2842"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
